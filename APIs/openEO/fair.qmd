---
title: "FAIR data & open science"
aliases:
  - /fair.html
---

## FAIR

One of the key goals of openEO, is to support [FAIR principles](https://www.go-fair.org/fair-principles/) and open science. The implementation in the Copernicus dataspace
makes it easier to comply with these principles, by incorporating these principles in the implementation, so that
users are automatically a step closer to generating FAIR-compliant open data. If your project has requirements related to these topics,
this should serve as a good starting point.

These are a few examples:

- *[F2 Rich metadata](https://www.go-fair.org/fair-principles/f2-data-described-rich-metadata/)* openEO generates rich STAC metadata,
  that includes processing info, complete raster metadata, band information, etcetera.
- *[R1.2 Detailed provenance](https://www.go-fair.org/fair-principles/r1-2-metadata-associated-detailed-provenance/)* In result metadata [derived-from](https://github.com/radiantearth/stac-spec/blob/master/item-spec/item-spec.md#derived_from)
  links link back to all input products to provide provenance.
- *[R1.3 use of domain relevant (meta)data standard](https://www.go-fair.org/fair-principles/r1-3-metadata-meet-domain-relevant-community-standards/)* openEO generates STAC metadata, so this one is included by default.
  For the data formats, it supports well known options such as Cloud optimized Geotiff, netCDF with CF conventions, GeoParquet, and many more.

## Open Science

With respect to open science, the main benefit of openEO is that your workflows can be stored in a standardized notation, in the
form of openEO 'process graphs'. This gives scientists a novel way of exchanging algorithms, without having to exchange a
complex code base. The key element is that openEO code or process graphs are often a lot easier to understand, because much
of the boilerplate logic is handled by the backend rather than by the user code.

This also has consequences for replicating work: the same process graph can be executed on different backends, or evaluated
against different datasets. This allows to evaluate whether an algorithm is broadly applicable, or only works in a very specific
environment.